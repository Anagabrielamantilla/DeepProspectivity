# -*- coding: utf-8 -*-
"""04_From_Scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/111gyUSVYdbOInvrDUrhQYrXB8KhDg3Oj
"""

# Elaborado por:
# Ana Mantilla : anagmd2019@gmail.com
# Paul Goyes : goyes.yesid@gmail.com

from google.colab import drive
drive.mount('/content/drive')

# Importar las librerías

import pandas as pd #usada para cargar los datos delimitados por comas (.csv)
import numpy as np #usada para extraer los valores de píxel del ráster en una matriz
import matplotlib.pyplot as plt #usada para gráficar
import tensorflow as tf #usada para crear el modelo de redes neuronales artificiales

#Importar los datos

df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PAPER_DL/TRAINING/02_Train_PCA.csv', sep=';')

# Visualizar la tabla de datos

df

df.shape

#Extraer las variables de entrada y de salida de la tabla

y_names=['DEP'] # Valores de salida-etiquetas de depósito (1) y no depósito (0)
y=df[y_names].values

x_names=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9']
X=df[x_names].values

# Crear el modelo from scratch


model = tf.keras.Sequential()
model.add(tf.keras.Input(shape=(9,))) # CAPA INPUT
model.add(tf.keras.layers.Dense(100, activation="relu")) # 1 CAPA OCULTA, TIENE 100 NEURONAS
model.add(tf.keras.layers.Dense(8, activation="relu")) # 2 CAPA OCULTA, TIENE 8 NEURONAS
model.add(tf.keras.layers.Dense(6, activation="relu")) # 3 CAPA OCULTA, TIENE 6 NEURONAS
model.add(tf.keras.layers.Dense(4, activation="relu")) # 4 CAPA OCULTA, TIENE 4 NEURONAS
model.add(tf.keras.layers.Dense(2, activation="relu")) # 5 CAPA OCULTA, TIENE 2 NEURONAS
model.add(tf.keras.layers.Dense(1, activation="sigmoid")) # CAPA DE SALIDA, TIENE UNA NEURONA, SE ACTIVA CON FUNCION SIGMODE PARA OBTENER VALORES ENTRE 0 Y 1

# Imprimir un resumen del modelo

model.summary()

# Imprimir un diagrama de grafo del modelo

tf.keras.utils.plot_model(model, show_shapes=True)

# Indicar el optimizador usado para el backpropagation y las métricas de evaluación

optimizer    = tf.keras.optimizers.Adam(learning_rate=1e-3)
loss_fn  = tf.keras.losses.BinaryCrossentropy() # tambien se puede indicar la función de perdida como las predeterminadas en keras

# Compilar el modelo con los hiperparámetros que se definieron anteriormente

model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])

#Entrenar el modelo

history= model.fit(
    x=X,
    y=y,
    batch_size=82,
    epochs=2000,
    )

# En la variable "history" quedan guardadas todas las métricas y funciones de perdida evaluadas en cada época.
# Podemos hacer una gráfica para cada una de ellas, primero vemos lo que podemos gráficar:


print(history.history.keys())

# Guardar las métricas en formato .npz

np.savez('/content/drive/MyDrive/Colab Notebooks/PAPER_DL/METRICAS-MODELOS/from_scratch.npz', loss=history.history['loss'], acc=history.history['accuracy'])

# Calcular la precisión y valor de la función de pérdida del entrenamiento

score= model.evaluate(X,y)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# Graficar las métricas

fig, ax1 = plt.subplots(1,1,figsize=(10,5))
ax1.tick_params(axis='y', labelcolor='blue')
ax1.plot(history.history['loss'],'b',label='LOSS')
ax1.set_ylabel('Función de pérdida', color='blue')
ax1.set_xlabel('Número de épocas', color='black')
ax2 = ax1.twinx()
ax2.set_ylabel('Precisión', color='red')
ax2.plot(history.history['accuracy'],'red')
ax2.tick_params(axis='y', labelcolor='red')

# Predecir los datos

pred_val = model.predict(X)

# Matriz de confusión

from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns

matriz3 = confusion_matrix(y, np.around(pred_val))
plot_confusion_matrix(conf_mat = matriz3, figsize = (5,5))

ax = plt.subplot()
sns.set(font_scale=1) # Adjust to fit
sns.heatmap(matriz3, annot=True, ax=ax, cmap="Blues", fmt="g");

# Labels, title and ticks
label_font = {'size':'18'}  # Adjust to fit
ax.set_xlabel('Predicted labels');
ax.set_ylabel('Observed labels',fontdict=label_font);

title_font = {'size':'18'}  # Adjust to fit
ax.set_title('Confusion Matrix', fontdict=title_font);

ax.tick_params(axis='both', which='major', labelsize=18)  # Adjust to fit
ax.xaxis.set_ticklabels(['False', 'True']);
ax.yaxis.set_ticklabels(['False', 'True']);

# Curva ROC

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve, auc

fpr_, tpr_, thresholds_ = roc_curve(y, pred_val)

plt.plot(fpr_, tpr_, marker='o')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.title('ROC CURVE')
plt.grid(True)

# Cálculo del AUC

from sklearn import metrics

print(f'El AUC para el modelo de bosques aleatorios es de: {metrics.auc(fpr_, tpr_)}')

# Guardar el modelo entrenado

model.save('/content/drive/MyDrive/Colab Notebooks/PAPER_DL/MODELOS-FINALES/from_scratch.h5')

# Cargar el virtual ráster que se descarga desde el link del repositorio

from osgeo import gdal

raster  = gdal.Open('/content/drive/MyDrive/Colab Notebooks/PAPER_DL/VIRTUAL_RASTER/02_PCA.tif') # Esta ruta cambia según dónde se guardó el archivo del virtual ráster

# Extraer las características del ráster

driver = raster.GetDriver()
col   = raster.RasterXSize #número de columnas
rows  = raster.RasterYSize #número de filas
nelem = col*rows #número de píxeles

print('numero de filas: ', rows)
print('numero de columnas: ', col)

# Guardar las posiciones NonData del ráster. Solo se hace una vez para cualquier banda
# ya que las posiciones de Nonvalue deben ser las mismas para todas las bandas

Nonvalue = raster.GetRasterBand(1).GetNoDataValue()

Nonvalue

#Extraer los valores de cada banda

v1val = raster.GetRasterBand(1).ReadAsArray().flatten()
v2val = raster.GetRasterBand(2).ReadAsArray().flatten()
v3val = raster.GetRasterBand(3).ReadAsArray().flatten()
v4val = raster.GetRasterBand(4).ReadAsArray().flatten()
v5val = raster.GetRasterBand(5).ReadAsArray().flatten()
v6val = raster.GetRasterBand(6).ReadAsArray().flatten()
v7val = raster.GetRasterBand(7).ReadAsArray().flatten()
v8val = raster.GetRasterBand(8).ReadAsArray().flatten()
v9val = raster.GetRasterBand(9).ReadAsArray().flatten()

# Agrupar los valores tal que se forme una matriz de N X 10
# donde N es el número de muestras

DATA = np.stack((v1val,v2val,v3val,v4val,v5val,v6val,v7val,v8val,v9val),axis=1)


# Organizar los datos y eliminar las posiciones de NonData

NanValues = np.where(v1val == Nonvalue)[0]
cP        = np.arange(0,nelem)
cPP       = np.delete(cP, NanValues, axis=0)

XX = np.delete(DATA, NanValues, axis=0)

# Predecir los valores con el modelo entrenado

y_raster = model.predict(XX)

# Crear nuevamente el formato de datos para llevarlo al raster.
# Usaremos una variable nueva llena de zeros, en la cual insertaremos los NonValues y los valores de la predicción.
# el tamaño de esta variable será el mismo que el raster

Rasterdataarray = np.zeros((rows,col)).flatten()

# cPP contiene las posiciones donde van las predicciones
for i in range(cPP.shape[0]):
    Rasterdataarray[cPP[i]]=y_raster[i]

# NanValues contiene las posiciones donde van los NOnValues
for i in range(NanValues.shape[0]):
    Rasterdataarray[NanValues[i]]=Nonvalue


# guardar la predicción en un raster con las mismas caracteristicas del raster input

Rasterout = driver.Create('/content/drive/MyDrive/Colab Notebooks/PAPER_DL/MAPA_PROBABILIDAD/01_From_Scratch.tif', col, rows, 1, gdal.GDT_Float32) #esta ruta se modifica según donde desee que se guarde el mapa de probabilidad en su Google Drive
# Write metadata
Rasterout.SetGeoTransform(raster.GetGeoTransform())
Rasterout.SetProjection(raster.GetProjection())

Rasterout.GetRasterBand(1).WriteArray(Rasterdataarray.reshape(rows,col))
Rasterout.GetRasterBand(1).SetNoDataValue(Nonvalue)
Rasterout = None
del Rasterout

# Visualizar el mapa final de probabilidad

mask = Rasterdataarray!=-9999
v2 = Rasterdataarray[np.where(mask)]
v2 = v2.reshape(-1,961)
plt.figure(figsize=(10,10))
plt.imshow(v2,cmap='jet')
plt.colorbar(fraction=0.04)

"""# **Créditos**
---

* **Autores:**
  * [Ana Gabriela Mantilla, Geóloga](https://www.linkedin.com/in/ana-gabriela-mantilla-24377a21a)
  * [Paul Goyes Peñafiel, PhD (c)](https://www.linkedin.com/in/paul-goyes-0212b810/)
"""